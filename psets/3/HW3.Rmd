---
title: "HW3"
author: "Nikhil Gopal"
date: "10/2/2020"
output: pdf_document
---
Here is the code (the comments in my code are the explanations for the questions):

```{r}
#3.1

num_observations <- 15
mu_parameter <- 10

#X
var1 <- rnorm(num_observations, mean = mu_parameter, sd = 4)

epsilon <- rnorm(num_observations, mean = 0, sd =1)

#Y
var2 <- 9*var1 + epsilon

#Plot
plot(var1, var2)

#covariance
covariance <- cov(var1, var2)

#correlation
correlation <- cor(var1, var2)


#Our covariance was  about 169.399 and our correlation was about 0.999. #This means that generally, 
#our two variables are extremely related to each other. 
#This we would expect since Y is a function of X.


#3.2
abline(a = 90, b =0)

#sample average squared distances
sample_avg <- var(var2)*(num_observations-1)/num_observations

# 
#The expected value of the squared differences was 325, while the sample  #average squared distances was 
#1433.
#This means that we there was expected to be much less variability in the #data 
#than what was actually observed.
 

#3.3
abline(a = 0, b = 9, col = "blue")

#sample avg squared distance of Y - E(X)
sample_avg_y_minus_EX <- sum(epsilon^2)/num_observations



# The sample average squared distance was 1.28 and the expected was 1. 
#This makes a lot of sense because Y is defined
# as a function of X plus some error which is normally distributed,  
# which is why we see the sample distance being 
# different than the expected distance.
# 
```

Question 2:


#Variances can be added

$$\begin{aligned} E(Y) = E(9X+ \epsilon) = 9E(X) + E(\epsilon) = 90 \\
E\bigg((X-E(X)^2\bigg) = 4 \\
E\bigg((Y-E(Y)^2\bigg) = Var(Y) = Var(9X + \epsilon) \\ 
= Var(9X) + Var(\epsilon) = 81Var(X) + 1 = 81(4) + 1 = 325 \end{aligned}$$


Question 3:

$$\begin{aligned}E(Y|X) = E(9X + \epsilon|X) = E((9X + \epsilon - 9X)^2) = Var(\epsilon) = 1 \end{aligned} $$


















